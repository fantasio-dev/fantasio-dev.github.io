---
layout: default
title: LSTM (Long Short Term Memory)
parent: 1. 기계학습
grand_parent: AI (인공지능)
nav_order: 13
---

# LSTM (Long Short Term Memory)
{: .fs-8 }

기계학습
{: .label .label-blue }

---

## 🎯 기술사 수준 설명

### 📌 핵심 암기 (Quick Reference)

{: .highlight }
> **LSTM**: 긴 시퀀스 학습이 가능한 RNN 구조, 기울기 소실 해결
> - (구성) `잊입출셀` 잊기게이트, 입력게이트, 출력게이트, 셀상태
> - ⭐ **차별점**: 게이트 메커니즘으로 장기 의존성 문제 해결

---

## 핵심 키워드

`게이트` `Cell State` `장기의존성` `기울기소실`

---

## 정의/개념

긴 시퀀스 학습이 가능한 RNN 구조, 기울기 소실 해결

---

## 구성 `잊입출셀`

| 암기 | 구성요소 | 설명 |
|:-----|:---------|:-----|
| **잊** | Forget Gate | 과거 정보 삭제 비율 결정 |
| **입** | Input Gate | 새 정보 저장 비율 결정 |
| **출** | Output Gate | 출력할 정보 결정 |
| **셀** | Cell State | 장기 기억 저장소 |

---

## LSTM 구조

```
                ┌─────────────────────────────────┐
                │         Cell State (C)          │
                │    ─────────────────────────    │
                │      ×        +        ×        │
                └──────↑────────↑────────↑────────┘
                       │        │        │
                ┌──────┴──┐ ┌───┴───┐ ┌──┴──────┐
                │ Forget  │ │ Input │ │ Output  │
                │  Gate   │ │ Gate  │ │  Gate   │
                └─────────┘ └───────┘ └─────────┘
                     ▲          ▲          ▲
                     └──────────┼──────────┘
                                │
                    ┌───────────┴───────────┐
                    │  h(t-1) concat x(t)   │
                    └───────────────────────┘
```

---

## LSTM vs RNN

| 항목 | RNN | LSTM |
|:-----|:----|:-----|
| **장기 의존성** | 불가 | 가능 |
| **기울기 소실** | 발생 | 해결 |
| **복잡도** | 단순 | 복잡 |
| **학습 속도** | 빠름 | 느림 |

---

## 연계 토픽

- [RNN]({{ site.baseurl }}/docs/ai/01-machine-learning/rnn)
- [기울기소실 문제]({{ site.baseurl }}/docs/ai/01-machine-learning/vanishing-gradient)

---

## 학습 체크리스트

- [ ] LSTM 정의 암기
- [ ] `잊입출셀` 구성요소 4가지 역할 설명
- [ ] RNN과의 차이점 설명
