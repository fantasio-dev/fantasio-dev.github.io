---
layout: default
title: 역전파 알고리즘
parent: 1. 기계학습
grand_parent: AI (인공지능)
nav_order: 14
---

<!-- CSV_APPLIED: 기술사_기본필수노트_AI - AI.csv | NO=5 | 중토픽=퍼셉트론 (Perceptron) -->
# 역전파 알고리즘
{: .fs-8 }

6. 퍼셉트론
{: .label .label-purple }

---

## 🎯 기술사 수준 설명

### 📌 핵심 암기 (Quick Reference)

{: .highlight }
> **퍼셉트론 (Perceptron)**: 인간의 신경망과 유사하게 만든 입력층, 은닉층, 출력층으로 구성되어진 학습 능력을 가진 신경망 모델
> - 암기: `단층다층,` `신경망분석` `입은활출` `항시렐계`
> - 키워드: `퍼셉트론` `편향` `가중치 입력값 곱`

---

<div class="exam-concept-block" markdown="1">

## 🧠 개념 영역

### 🔑 핵심 키워드 3개

| 키워드 | 설명 | 예시 |
|:--|:--|:--|
| **퍼셉트론** | 핵심 개념/대상 | - |
| **편향** | 주요 기법/구성요소 | - |
| **가중치 입력값 곱** | 절차/평가/특징 | - |

---

### 📖 등장배경

| 구분 | 내용 |
|:--|:--|
| **문제/필요성** | 인간의 신경망과 유사하게 만든 입력층, 은닉층, 출력층으로 구성되어진 학습 능력을 가진 신경망 모델 |
| **활용/사례** | - |

---

### 📝 개념 정의

| 구분 | 정의 |
|:--|:--|
| **퍼셉트론 (Perceptron)** | 인간의 신경망과 유사하게 만든 입력층, 은닉층, 출력층으로 구성되어진 학습 능력을 가진 신경망 모델 |

</div>

---

<div class="exam-tech-block" markdown="1">

## 🏗️ 기술 영역

### 구성요소

#### 그룹 1: 구성요소
{: .highlight-purple }

| 항목 | 설명 |
|:--|:--|
| **> 입력Layer** | 기초데이터입력 |
| **> 은닉Layer** | - |
| **>가중치, Bias(편향), Net Input Function(가중치 입력값 곱), 활성화 함수, Critical Point(활성화최소값)** | - |
| **> 출력Layer** | 출력값 |


</div>

---

<details markdown="1">
<summary><h3 style="display:inline">📖 상세 설명 (클릭해서 펼치기)</h3></summary>

#### 내용

- 인간의 신경망과 유사하게 만든 입력층, 은닉층, 출력층으로 구성되어진 학습 능력을 가진 신경망 모델

#### 유형

- > 단층퍼셉트론: AND, OR, NAND
- > 다층퍼셉트론: XOR처리 가능, 은닉층추가, bias(편향)

#### 구성요소

- > 입력Layer: 기초데이터입력
- > 은닉Layer
- >가중치, Bias(편향), Net Input Function(가중치 입력값 곱), 활성화 함수, Critical Point(활성화최소값)
- > 출력Layer: 출력값

#### 활성화함수

- 일정 범위값 변환 전달, 단조 증가 함수
- > 항등함수: f(x) = x, 선형출력
- > 시그모이드함수: y=1/1+e^ > x, 0과 1사이, 0.5기준
- > ReLU함수: ReLU(x) = { 0 if x < 0, x if x >= 0 }, 0보다 크면 x
- > 계단함수: f(NET) = { 1 if NET >= T, 0 if NET < T, 기준값 T기준 0 아니면 1

</details>

---

<details markdown="1">
<summary><h3 style="display:inline">🗂️ 기존 내용 (백업)</h3></summary>

# 인공신경망 오류 역전파(Backpropagation) 알고리즘
{: .fs-8 }

6. 퍼셉트론
{: .label .label-purple }

---

## 핵심 키워드

`역전파` `가중치 갱신` `Epoch`

---

## 정의/개념

인공신경망의 출력값이 원하는 출력과 다를 경우, 가중치를 갱신하여 오차 최소화시키도록 반복 수행 신경망 학습 알고리즘

> 출력층의 결과를 비교하여 오차가 이을 경우 역전파하여 은닉층의 가중치를 조정하여 갱신

---

## 개념도

```
                Hidden Layer         Output Layer
                                        Error
    Input  ─────→ ○ ──────────────────→ 0.36
       1         ╱│╲         ①          ↓
                ╱ │ ╲                   ③
               ╱  │  ╲                  ↓
              ②   │   ②                 ②
             ╱    │    ╲               ↓
            ╱     │     ╲            Error
    Input  ─────→ ○ ───────→        0.6
       2          ④

                                      Error
                                      0.24
```

---

## 프로세스

| # | 프로세스 | 핵심 |
|:--|:--------|:-----|
| 1 | **피드포워드** | 입력층 → 출력층 순전파 수행 |
| 2 | **오류역전파 계산** | 출력층부터 가중치 탐색, 출력층에서 역방향 진행 |
| 3 | **가중치 조정** | 학습률만큼 수정한 가중치 조정 |
| 4 | **반복 수행** | N회 epoch 수행 |

---

## 문제점 및 해결방안

| 구분 | 항목 | 핵심 |
|:-----|:-----|:-----|
| **문제점** | Sigmoid 함수 문제 | 기울기 소실문제 발생 |
| **해결방안** | ReLU 사용 | max(0,x) 함수 적용 |

---

## 연계 토픽

- [경사하강법](/docs/ai/01-machine-learning/activation-function)
- [기울기 소실](/docs/ai/01-machine-learning/vanishing-gradient)
- [MLP](/docs/ai/02-deep-learning/mlp)

---

## 학습 체크리스트

- [ ] 역전파 알고리즘의 정의와 개념도 이해
- [ ] 프로세스 4단계(피드포워드-오류역전파-가중치조정-반복) 암기
- [ ] Sigmoid 문제점과 ReLU 해결방안 파악


</details>

