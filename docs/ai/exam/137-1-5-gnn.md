---
layout: default
title: 137회-1교시-5번 GNN(Graph Neural Network)을 설명하시오
parent: 📝 기출문제
grand_parent: AI (인공지능)
nav_order: 1371105
permalink: /docs/ai/exam/137-1-5-gnn
---

# GNN(Graph Neural Network)을 설명하시오
{: .no_toc }

137회 정보관리기술사 1교시 5번
{: .label .label-blue }

1교시형 (단답형)
{: .label .label-red }

---

## ✅ 문제

GNN(Graph Neural Network)을 설명하시오

---

## 📚 목차
{: .no_toc .text-delta }

- [🎓 고딩 수준 설명](#-고딩-수준-설명)
- [🎯 기술사 수준 설명](#-기술사-수준-설명)

---

<details markdown="1">
<summary><h2 style="display:inline" id="-고딩-수준-설명">🎓 고딩 수준 설명 (클릭해서 펼치기)</h2></summary>

### 🔑 핵심 키워드 3개

| 키워드 | 설명 |
|:------|:-----|
| **관계(그래프)** | 친구 관계/연결처럼 "누가 누구와 연결됐는지" 구조 |
| **메시지 패싱** | 이웃 노드 정보를 모아 내 정보를 업데이트 |
| **Readout(요약)** | 노드들을 합쳐 그래프 전체의 대표값을 만드는 단계 |

### 📖 등장배경

| 구분 | 내용 |
|:-----|:-----|
| **과거** | CNN/RNN은 격자(이미지)·순서(문장)에는 강하지만, **관계가 핵심인 데이터**는 표현 어려움 |
| **문제** | 소셜 네트워크, 지식 그래프, 분자 구조 등 **연결 구조를 살려서 학습** 필요 |

### 📝 개념 정의
> **GNN**: 그래프(노드·엣지) 구조 데이터를 학습해서 **노드/엣지/그래프**의 특성을 예측하는 신경망

### 🧩 기술요소/구성요소 (2그룹 × 4개)

| 그룹 | 세부 항목(4개) |
|:--|:--|
| A (입력 표현) | 인접행렬(Adjacency), 노드특징행렬(Node Feature), 엣지특징(Edge Feature), 라플라시안/스펙트럼(선택) |
| B (학습 흐름) | Message 생성, Aggregate(취합), Update/Combine(업데이트), Readout(생성/요약) |

### ⭐ 차별점 키워드
- **Permutation Invariance(순서 불변성)**: 노드의 "나열 순서"가 바뀌어도 같은 결과를 내야 함

### 🧾 6하원칙 요약

| 항목 | 내용 |
|:-----|:-----|
| **누가(Who)** | 각 **노드**가 |
| **언제(When)** | 각 **레이어**마다 |
| **어디서(Where)** | 자신의 **이웃 노드**로부터 |
| **무엇을(What)** | 정보를 받아(메시지) |
| **왜(Why)** | 관계를 반영한 표현(embedding)을 만들기 위해 |
| **어떻게(How)** | `Message → Aggregate → Update → (Readout)`로 |
| **결과(Result)** | 노드/엣지/그래프 예측 성능 향상 |

</details>

---

## 🎯 기술사 수준 설명
{: #-기술사-수준-설명}

### 📌 핵심 암기 (Quick Reference)

{: .highlight }
> **GNN**: 그래프관계학습, 메시지패싱, Readout → 그래프 구조 데이터용 신경망
> - (입력 표현) `인노엣라` - 인접행렬→노드특징→엣지특징→라플라시안
> - (학습 흐름) `변취업생` - 변환→취합→업데이트→생성/요약
> - (대표 모델) `GCN-SAGE-GAT-GIN`

---

## 🧠 개념 영역


### 🔑 핵심 키워드 3개

| 키워드 | 설명 | 예시 |
|:------|:-----|:-----|
| **관계(그래프)** | 노드와 엣지로 데이터 간 연결 구조 표현 | 소셜 네트워크, 분자 구조 |
| **메시지 패싱** | 이웃 노드 정보를 모아 자신의 표현을 업데이트 | k-layer = k-hop 이웃 반영 |
| **순서 불변성** | 노드 순서가 바뀌어도 동일 결과 보장 | Sum/Mean/Max 집계 |

---

### 📖 등장배경

| 구분 | 내용 |
|:-----|:-----|
| **기술환경 변화** | CNN/RNN은 격자·순서 데이터에 특화 → **비정형(Non-Euclidean) 그래프 데이터** 처리 필요성 증가 |
| **비즈니스 요구** | 소셜 네트워크, 추천 시스템, 분자/약물 분석 등 **관계 기반 예측** 수요 급증 |

---

### 📝 개념 정의

| 구분 | 정의 (22자 이내) |
|:-----|:----------------|
| **GNN** | 그래프 구조 데이터를 학습하는 신경망 |

---

## 🏗️ 기술 영역

<div class="exam-tech-block" markdown="1">

### 🏗️ 구성요소 (핵심 암기법 상세) `인노엣라` / `변취업생`

#### 그룹 1: 그래프 입력 표현 `인노엣라`

| 암기 | 항목 | 설명 | 예시 |
|:-----|:-----|:-----|:-----|
| **인** | 인접행렬(Adjacency Matrix) | 노드 간 연결 정보를 표현 | \(A_{uv}=1\)이면 연결 |
| **노** | 노드특징행렬(Node Feature) | 노드의 속성(피처) | 사용자 프로필 벡터 |
| **엣** | 엣지특징(Edge Feature) | 엣지의 타입/가중치/속성 | 관계 타입, 거리, 시간 |
| **라** | 라플라시안/스펙트럼(선택) | 그래프 구조를 스펙트럼 관점에서 표현 | \(L=D-A\) |

#### 그룹 2: 메시지 패싱 파이프라인 `변취업생`

| 암기 | 항목 | 설명 | 예시 |
|:-----|:-----|:-----|:-----|
| **변** | Message(변환) | 이웃에게 전달할 정보 생성 | 선형변환/MLP |
| **취** | Aggregate(취합) | 이웃 메시지 집계 | Sum/Mean/Max/Attention |
| **업** | Update/Combine(업데이트) | 취합 결과로 노드 표현 갱신 | GRU/MLP/Residual |
| **생** | Readout(생성/요약) | 노드→그래프 대표값으로 요약 | Global Pooling |

---

</div>
## ⭐ 차별점 키워드 (가산점 포인트)

{: .important }
> **Permutation Invariance (순서 불변성)**
> - 노드의 **나열 순서가 바뀌어도 동일한 결과** 보장
> - 집계 함수(Sum/Mean/Max)가 순서에 무관하게 설계됨
> - 그래프 구조 자체가 중요하지, 노드 번호/순서는 무의미

---

<details markdown="1">
<summary><h3 style="display:inline">🧠 상세 설명 (클릭해서 펼치기)</h3></summary>

#### 📖 등장배경 상세

```
🌐 과거: CNN/RNN은 격자(이미지)·순서(문장)에는 강하지만, 관계가 핵심인 데이터는 표현 어려움

💡 문제: "소셜 네트워크/지식 그래프/분자 구조처럼 연결 구조를 살려서 학습하려면?"

✅ 해결: GNN으로 그래프 구조 직접 학습!
   → 그래프를 그대로 입력으로 받아
   → 레이어마다 이웃 정보를 취합(aggregate)해서
   → 노드 표현을 갱신(update)하고
   → 필요하면 그래프 단위로 요약(readout)
```

---

#### 🔄 메시지 패싱 구조도 (ASCII)

```
┌─────────────────────────────────────────────────────────────┐
│                    Message Passing Layer                     │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│   [Node v]                                                   │
│      ↑                                                       │
│   ┌──┴──────────────────────────────────────────────────┐   │
│   │              UPDATE (업데이트)                        │   │
│   │   h_v^(k) = UPDATE(h_v^(k-1), AGG({h_u}))           │   │
│   └────────────────────────┬────────────────────────────┘   │
│                            ↑                                 │
│   ┌────────────────────────┴────────────────────────────┐   │
│   │              AGGREGATE (취합)                        │   │
│   │         Sum / Mean / Max / Attention                 │   │
│   └────────────────────────┬────────────────────────────┘   │
│              ↑             ↑             ↑                   │
│   ┌──────────┴──┐  ┌───────┴──┐  ┌───────┴──┐               │
│   │  Neighbor 1 │  │ Neighbor 2│  │ Neighbor 3│               │
│   │   h_u1      │  │   h_u2    │  │   h_u3    │               │
│   └─────────────┘  └──────────┘  └──────────┘               │
│                                                              │
│   ※ k-layer → k-hop 이웃 정보까지 반영 가능                  │
└─────────────────────────────────────────────────────────────┘
```

---

#### 📊 GNN 핵심 수식

$$
\mathbf{h}_v^{(k)}=\text{UPDATE}\left(\mathbf{h}_v^{(k-1)},\text{AGG}\left(\{\mathbf{h}_u^{(k-1)}|u\in\mathcal{N}(v)\}\right)\right)
$$

| 기호 | 설명 |
|:-----|:-----|
| \(\mathbf{h}_v^{(k)}\) | k번째 레이어에서 노드 v의 표현(임베딩) |
| \(\mathcal{N}(v)\) | 노드 v의 이웃 노드 집합 |
| AGG | 이웃 정보 집계 함수 (Sum/Mean/Max/Attention) |
| UPDATE | 집계 결과로 노드 표현 갱신 |

---

#### 💼 활용 사례

| 분야 | 활용 | 설명 |
|:-----|:-----|:-----|
| **추천 시스템** | 사용자-아이템 그래프 | 관계 기반 개인화 추천 |
| **소셜 네트워크** | 커뮤니티 탐지/친구 추천 | 사용자 관계 분석 |
| **분자/바이오** | 약물-단백질 상호작용 | 분자 물성 예측 |
| **교통/네트워크** | 도로/망 최적화 | 교통 흐름 예측 |
| **지식 그래프** | 엔티티 관계 학습 | QA, 추론 |

---

#### 📈 상위 토픽 계층도

```
딥러닝 아키텍처
├── CNN (격자 데이터)
├── RNN/Transformer (순차 데이터)
└── GNN (그래프 데이터) ⭐
    ├── 입력 표현: 인노엣라
    ├── 학습 흐름: 변취업생
    ├── 대표 모델
    │   ├── GCN
    │   ├── GraphSAGE
    │   ├── GAT
    │   └── GIN
    └── 활용 분야
        ├── 추천 시스템
        ├── 소셜 네트워크
        ├── 분자/바이오
        └── 지식 그래프
```

---

#### ✅ 학습 체크리스트

- [ ] GNN 정의 22자로 말할 수 있다
- [ ] 입력 표현 `인노엣라` 4요소 설명 가능
- [ ] 메시지 패싱 `변취업생` 4단계 설명 가능
- [ ] 대표 모델 `GCN-SAGE-GAT-GIN` 각각의 특징 설명 가능
- [ ] 순서 불변성(Permutation Invariance) 개념 설명 가능
- [ ] 예측 레벨 3가지(노드/엣지/그래프) 설명 가능

</details>

---



<details markdown="1">
<summary><h3 style="display:inline">🧠 상세 설명 (클릭해서 펼치기)</h3></summary>

### 📊 대표 모델 비교 `GCN-SAGE-GAT-GIN`

| 모델 | 핵심 특징 | 장점 |
|:-----|:---------|:-----|
| **GCN** | 그래프 합성곱(스펙트럼/공간) 기반 | 대표적 GNN 모델 |
| **GraphSAGE** | 이웃 샘플링+집계 | 대규모 그래프 확장성 |
| **GAT** | Attention으로 이웃 중요도 차등 반영 | 중요한 이웃에 집중 |
| **GIN** | 그래프 구조 구분(표현력) 강화 | WL-test와 동등한 표현력 |

---

### 📊 예측 레벨 비교

| 대상 | 설명 | 예시 |
|:-----|:-----|:-----|
| **노드(Node) 레벨** | 각 노드에 대해 분류/회귀 | 사용자/계정 분류, 문서 분류 |
| **엣지(Edge) 레벨** | 연결 여부/관계 강도 예측 | 링크 예측, 추천(사용자-아이템) |
| **그래프(Graph) 레벨** | 전체 그래프 단위 분류/회귀 | 분자 독성/물성 예측, 그래프 분류 |

---

</details>
## 참고(출처/메모)

- 키워드: 인접행렬, 노드특징행렬, 취합(aggregate), 업데이트(update), 생성(readout), GCN
