---
layout: default
title: 135회-1교시-1번 PR 곡선과 ROC 곡선 비교
parent: 📝 기출문제
grand_parent: AI (인공지능)
nav_order: 1351101
permalink: /docs/ai/exam/135-1-1-pr-roc
---

# PR(Precision Recall) 곡선과 ROC(Receiver Operating Characteristic) 곡선 비교
{: .no_toc }

135회 정보관리기술사 1교시 1번
{: .label .label-blue }

1교시형 (단답형) - 비교형
{: .label .label-red }

---

## ✅ 문제

PR(Precision Recall) 곡선과 ROC(Receiver Operating Characteristic) 곡선 비교

---

## 📚 목차
{: .no_toc .text-delta }

- [🎓 고딩 수준 설명](#-고딩-수준-설명)
- [🎯 기술사 수준 설명](#-기술사-수준-설명)

---

<details markdown="1">
<summary><h2 style="display:inline" id="-고딩-수준-설명">🎓 고딩 수준 설명 (클릭해서 펼치기)</h2></summary>

### 🔑 핵심 키워드 3개

| 키워드 | 설명 |
|:------|:-----|
| **정밀도/재현율** | 예측이 얼마나 정확한지 / 실제 양성을 얼마나 찾았는지 |
| **클래스 불균형** | 양성 데이터가 음성보다 훨씬 적은 상황 (예: 암 환자 1%) |
| **AUC** | 곡선 아래 면적, 1에 가까울수록 좋은 모델 |

### 📖 등장배경

| 구분 | 내용 |
|:-----|:-----|
| **과거** | AI 모델 성능을 정확도(Accuracy)만으로 평가 |
| **문제** | 암 환자가 1%인데, 무조건 '정상'이라고 하면 99% 정확도? |

### 📝 개념 정의

| 개념 | 정의 | 쉬운 비유 |
|:-----|:-----|:---------|
| **PR 곡선** | 정밀도와 재현율의 관계를 나타내는 곡선 | 암 검진에서 "암이다"라고 예측한 것 중 진짜 암 환자 비율 |
| **ROC 곡선** | TPR과 FPR의 관계를 나타내는 곡선 | 전체적으로 암 환자와 정상인을 얼마나 잘 구분하는지 |

### 🏗️ 기술요소 (2그룹 × 4개)

#### 그룹 1: PR 곡선 핵심 `정재불양`

| 요소 | 설명 |
|:-----|:-----|
| **정**밀도(Precision) | 양성 예측 중 실제 양성 비율 |
| **재**현율(Recall) | 실제 양성 중 양성으로 예측한 비율 |
| **불**균형 | 클래스 불균형 데이터에 적합 |
| **양**성 집중 | 양성 클래스 성능에 집중 |

#### 그룹 2: ROC 곡선 핵심 `참거전균`

| 요소 | 설명 |
|:-----|:-----|
| **참** 양성률(TPR) | 실제 양성 중 양성 예측 비율 |
| **거**짓 양성률(FPR) | 실제 음성 중 양성으로 잘못 예측 비율 |
| **전**체 평가 | 양성+음성 종합 평가 |
| **균**형 데이터 | 균형 데이터에 적합 |

### ⭐ 차별점 키워드

**"불균형 데이터는 PR 곡선, 균형 데이터는 ROC 곡선"** - 데이터 분포에 따라 적합한 평가 지표 선택

### 🧾 6하원칙 요약

| 항목 | PR 곡선 | ROC 곡선 |
|:-----|:--------|:---------|
| **누가** | 불균형 데이터 분석가 | 일반 분류 모델 평가자 |
| **언제** | 양성 클래스가 중요할 때 | 전체 분류 성능 평가할 때 |
| **어디서** | 질병 진단, 스팸 탐지 | 이미지 분류, 일반 분류 |
| **무엇을** | 정밀도-재현율 관계 | TPR-FPR 관계 |
| **어떻게** | X축: 재현율, Y축: 정밀도 | X축: FPR, Y축: TPR |
| **왜** | 양성 예측 성능 정밀 분석 | 전체적인 분류 능력 파악 |

</details>

---

## 🎯 기술사 수준 설명
{: #-기술사-수준-설명}

### 📌 핵심 암기 (Quick Reference)

{: .highlight }
> **PR/ROC 곡선**: 불균형 데이터 분류 평가 필요 → 정밀도, 재현율, TPR, FPR → 이진 분류 모델 성능 평가 곡선
> - ⭐ **(비교 8가지)** `축목불곡AUC장단사` - 축구성, 목적, 불균형영향, 곡선형태, AUC해석, 장점, 단점, 사례
> - (PR 곡선) `정재F1` - 정밀도, 재현율, F1-Score
> - (ROC 곡선) `참거특` - 참긍정률, 거짓긍정률, 특이도
> - (불균형해결) `언오` - 언더샘플링, 오버샘플링
> - ⭐ **차별점**: 불균형 데이터 → **PR 곡선** (질병탐지, 스팸) / 균형 데이터 → **ROC 곡선** (이미지분류)

---

<div class="exam-concept-block" markdown="1">

## 🧠 개념 영역


### 🔑 핵심 키워드 3개

| 키워드 | 설명 | 예시 |
|:------|:-----|:-----|
| **정밀도/재현율** | PR 곡선의 핵심 지표, Trade-off 관계 | Precision, Recall |
| **TPR/FPR** | ROC 곡선의 핵심 지표, 민감도와 특이도 | 민감도, 1-특이도 |
| **클래스 불균형** | 양성/음성 비율 차이에 따른 평가 지표 선택 | 암 환자 1%, 정상 99% |

---

### 📖 등장배경

| 구분 | 내용 |
|:-----|:-----|
| **기술환경 변화** | 정확도(Accuracy)만으로 분류 모델 성능 평가 → **다각도 평가 지표** 필요 |
| **비즈니스 요구** | 클래스 불균형 시 정확도는 의미 없음 → **상황별 최적 평가 지표** 선택 필요 |

---

### 📝 개념 정의

| 구분 | 정의 (22자 이내) |
|:-----|:----------------|
| **PR 곡선** | 정밀도와 재현율의 관계를 나타내는 곡선 |
| **ROC 곡선** | TPR과 FPR의 관계를 나타내는 곡선 |

---

</div>

## 🏗️ 기술 영역

<div class="exam-tech-block" markdown="1">

### 📊 PR 곡선 vs ROC 곡선 상세 비교 `축목불곡AUC장단사`

| 암기 | 비교 항목 | PR 곡선 | ROC 곡선 |
|:-----|:---------|:--------|:---------|
| **축** | 축 구성 | X: 재현율(Recall), Y: 정밀도(Precision) | X: 거짓 양성률(FPR), Y: 참 양성률(TPR) |
| **목** | 목적 | **불균형 데이터**에서 긍정 클래스 예측 성능 평가 | **균형 데이터**에서 모델의 전체적인 예측 성능 평가 |
| **불** | 불균형 영향 | **클래스 불균형에 민감**, 긍정 클래스 성능 변화에 집중 반응 | 불균형 데이터에서 성능 해석이 왜곡될 가능성, **둔감하게 반응** |
| **곡** | 곡선 형태 | 정밀도와 재현율 간의 균형, **오른쪽 위에 붙어 있는 형태** | TPR과 FPR의 관계, **왼쪽 위에 붙어 있는 형태** |
| **AUC** | AUC 해석 | AUC-PR 값이 클수록 **긍정 클래스 예측이 우수** | AUC-ROC 값이 클수록 **전체 분류 성능이 우수** |
| **장** | 장점 | 클래스 불균형 데이터에서 **긍정 클래스 성능 평가에 유용** | 모델의 **전반적인 분류 성능 및 모델 간 비교에 유용**, 해석 용이 |
| **단** | 단점 | ROC만큼 널리 사용되지 않음, AUC-PR 해석이 직관적이지 않음 | 불균형 데이터에서 **성능 과대평가 가능**, 긍정 클래스 세밀 분석 어려움 |
| **사** | 사례 | **희귀 이벤트 예측** (질병 탐지, 스팸 필터링) | **전체적인 모델 성능 평가** (이미지 분류) |

---

### 🏗️ 구성요소

#### 그룹 1: PR 곡선 지표 `정재F1`

| 암기 | 지표 | 공식 | 설명 | 예시 |
|:-----|:-----|:-----|:-----|:-----|
| **정** | 정밀도(Precision) | TP / (TP + FP) | 양성 예측 중 실제 양성 비율 | 암이라고 예측한 것 중 실제 암 |
| **재** | 재현율(Recall) | TP / (TP + FN) | 실제 양성 중 양성으로 예측한 비율 | 실제 암 환자 중 암 예측 |
| **F1** | F1-Score | 2×(P×R)/(P+R) | 정밀도와 재현율의 조화 평균 | 불균형 데이터 종합 지표 |

#### 그룹 2: ROC 곡선 지표 `참거특`

| 암기 | 지표 | 공식 | 설명 | 예시 |
|:-----|:-----|:-----|:-----|:-----|
| **참** | 참 긍정률(TPR) | TP / (TP + FN) | 민감도(Sensitivity), 재현율과 동일 | 실제 양성 탐지율 |
| **거** | 거짓 긍정률(FPR) | FP / (FP + TN) | 실제 음성 중 양성으로 잘못 예측 비율 | 오탐률 |
| **특** | 특이도(Specificity) | 1 - FPR | 실제 음성 중 음성으로 정확히 예측 비율 | TN / (FP + TN) |

---

### 📉 클래스 불균형 해결방법 `언오`

| 암기 | 방법 | 기법 | 설명 |
|:-----|:-----|:-----|:-----|
| **언** | 언더샘플링 | Tomek Link, ENN | 다수 클래스 데이터 축소 |
| **오** | 오버샘플링 | ADASYN, SMOTE | 소수 클래스 데이터 증강 |

---

</div>
<div class="exam-bonus-block" markdown="1">

## ⭐ 차별점 키워드 (가산점 포인트)

{: .important }
> **데이터 분포에 따른 평가 지표 선택**
> - **불균형 데이터** (양성 비율 낮음): **PR 곡선** 사용 → 희귀질병 탐지, 스팸 필터링
> - **균형 데이터** (양성/음성 비율 유사): **ROC 곡선** 사용 → 이미지 분류, 일반 분류
> - PR 곡선과 ROC 곡선은 서로 다른 평가 기준을 제공하므로, 문제의 특성과 목표에 맞게 선택

---

</div>

<details markdown="1">
<summary><h3 style="display:inline">🧠 상세 설명 (클릭해서 펼치기)</h3></summary>

#### 📖 등장배경 상세

```
🌐 과거: 정확도(Accuracy)만으로 분류 모델 성능 평가

💡 문제: "클래스 불균형 시 정확도는 의미 없음 (99% 음성이면 무조건 음성 예측해도 99%)"

✅ 해결: 이진 분류 모델의 성능을 다각도로 평가!
   → PR 곡선: 불균형 데이터에서 양성 클래스 중심 평가
   → ROC 곡선: 균형 데이터에서 전체적인 분류 성능 평가
   → 최적의 임계점을 찾는 데 도움
```

---

#### 🔄 혼동 행렬(Confusion Matrix)

```
                        예측 (Predicted)
                    ┌─────────────┬─────────────┐
                    │   Positive  │   Negative  │
        ┌───────────┼─────────────┼─────────────┤
 실제   │ Positive  │     TP      │     FN      │
(Actual)│           │ (True Pos)  │ (False Neg) │
        ├───────────┼─────────────┼─────────────┤
        │ Negative  │     FP      │     TN      │
        │           │ (False Pos) │ (True Neg)  │
        └───────────┴─────────────┴─────────────┘

• Precision = TP / (TP + FP)  ← 양성 예측의 정확도
• Recall = TPR = TP / (TP + FN)  ← 양성 탐지율
• FPR = FP / (FP + TN)  ← 오탐률
• Specificity = TN / (FP + TN) = 1 - FPR
```

---

#### 🔄 PR 곡선 vs ROC 곡선 그래프

```
        PR Curve                          ROC Curve
        (Precision-Recall)                (Receiver Operating Characteristic)
        
   1.0 ┤                              1.0 ┤      .---------
       │    .-------.                     │    ./
   0.8 ┤   /         \                0.8 ┤   /
       │  /           \                   │  /
   0.6 ┤ /             \              0.6 ┤ /
 P     │/               \           T     │/
 r  0.4┤                 \          P  0.4┤
 e     │                  \         R     │
 c  0.2┤ ................. \        │  0.2┤
 i     │ (무작위: 양성비율)  \           │...(무작위: 대각선)
 s  0.0┼───────────────────────      0.0 ┼───────────────────────
 i     0.0  0.2  0.4  0.6  0.8  1.0       0.0  0.2  0.4  0.6  0.8  1.0
 o            Recall                             FPR (False Positive Rate)
 n
        
   • X축: 재현율(Recall)                • X축: 거짓 양성률(FPR)
   • Y축: 정밀도(Precision)             • Y축: 참 양성률(TPR)
   • 오른쪽 위 = 좋은 모델               • 왼쪽 위 = 좋은 모델
   • AUC-PR: 곡선 아래 면적              • AUC-ROC: 곡선 아래 면적
```

---

#### 📈 상위 토픽 계층도

```
머신러닝 모델 평가
├── 분류 모델 평가 지표
│   ├── 기본 지표
│   │   ├── Accuracy (정확도)
│   │   ├── Precision (정밀도)
│   │   ├── Recall (재현율)
│   │   └── F1-Score
│   ├── 곡선 기반 평가 ⭐
│   │   ├── PR 곡선 (불균형 데이터)
│   │   │   └── AUC-PR
│   │   └── ROC 곡선 (균형 데이터)
│   │       └── AUC-ROC
│   └── 혼동 행렬 (Confusion Matrix)
│       ├── TP, TN, FP, FN
│       ├── TPR (민감도/재현율)
│       ├── FPR (거짓 양성률)
│       └── Specificity (특이도)
└── 클래스 불균형 해결
    ├── 언더샘플링 (Tomek Link, ENN)
    └── 오버샘플링 (SMOTE, ADASYN)
```

---

#### ✅ 학습 체크리스트

- [ ] PR 곡선 정의 22자로 말할 수 있다
- [ ] ROC 곡선 정의 22자로 말할 수 있다
- [ ] PR 곡선의 축 구성 (X: 재현율, Y: 정밀도) 설명 가능
- [ ] ROC 곡선의 축 구성 (X: FPR, Y: TPR) 설명 가능
- [ ] PR 곡선 지표 `정재F1` 공식 암기
- [ ] ROC 곡선 지표 `참거특` 공식 암기
- [ ] PR vs ROC 비교 8가지 `축목불곡AUC장단사` 암기
- [ ] 불균형 데이터에서 PR 곡선을 사용하는 이유 설명 가능
- [ ] 클래스 불균형 해결 방법 `언오` (언더샘플링, 오버샘플링) 설명 가능
- [ ] 실제 사례별 적합한 곡선 선택 가능 (질병탐지→PR, 이미지분류→ROC)

---

</details>
## 참고(출처/메모)

- 머신러닝 모델 평가 지표 교재
- 클래스 불균형 해결 기법 (SMOTE, Tomek Link)
