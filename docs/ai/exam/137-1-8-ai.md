---
layout: default
title: 137회-1교시-8번 AI 신뢰성 검인증 제도(CAT)를 설명하시오
parent: 📝 기출문제
grand_parent: AI (인공지능)
nav_order: 1371108
permalink: /docs/ai/exam/137-1-8-ai
---

# AI 신뢰성 검인증 제도(CAT)를 설명하시오
{: .no_toc }

137회 정보관리기술사 1교시 8번
{: .label .label-blue }

1교시형 (단답형)
{: .label .label-red }

---

## ✅ 문제

AI 신뢰성 검인증 제도(CAT)를 설명하시오

---

## 📚 목차
{: .no_toc .text-delta }

- [🎓 고딩 수준 설명](#-고딩-수준-설명)
- [🎯 기술사 수준 설명](#-기술사-수준-설명)

---

<details markdown="1">
<summary><h2 style="display:inline" id="-고딩-수준-설명">🎓 고딩 수준 설명 (클릭해서 펼치기)</h2></summary>

### 🔑 핵심 키워드 3개
- **인증(검인증)**: “이 AI는 믿을 만하다”를 점검/확인
- **거버넌스(Governance)**: AI를 책임 있게 만들고 운영하는 체계
- **추적/설명**: 어떤 데이터·모델로 어떤 결과가 나왔는지 확인 가능

### 📖 등장배경
- **과거**: 생성형 AI/AI 서비스가 급속히 확산되면서, 편향·오작동·안전·보안·저작권 등 문제가 사회/조직 리스크로 확대
- **문제**: “AI 모델/시스템을 누가, 어떤 기준으로, 얼마나 믿고 써도 되는지” 객관적으로 확인할 방법이 필요
- **해결**: **AI 신뢰성**(투명성/책임성/공정성/안전성/설명가능성 등)을 기준으로 **점검·평가·검증·확인**하고 **인증**하는 제도(CAT)

### 📝 개념 정의
> **CAT(Certification of AI Trustworthiness)**: AI 모델/시스템의 신뢰성을 **평가하여 인증**하는 제도

### 🧩 기술요소/구성요소 (2그룹 × 4개)

| 그룹 | 세부 항목(4개) |
|:--|:--|
| A (인증 범위) | AI 모델, AI 시스템, AI 거버넌스 체계, AI 제품 신뢰성 |
| B (핵심 점검축) | 위험관리, 거버넌스, 신뢰성 테스트, 추적가능성 |

### ⭐ 차별점 키워드
- **신뢰성(Trustworthiness) 중심**: “성능만 좋다”가 아니라 **책임·안전·공정·설명**까지 포함한 종합 평가

### 🧾 6하원칙 요약
- **누가(Who)**: 조직/기업이(또는 인증기관이)
- **언제(When)**: 개발/도입/운영 전후로
- **어디서(Where)**: AI 모델·시스템·거버넌스 전 영역에서
- **무엇을(What)**: 신뢰성 요구사항을
- **왜(Why)**: AI 리스크를 줄이고 책임 있는 활용을 위해
- **어떻게(How)**: `위거신추` 기반으로 평가하고 인증

</details>

---

## 🎯 기술사 수준 설명
{: #-기술사-수준-설명}

### 📌 핵심 암기 (Quick Reference)

{: .highlight }
> **CAT**: 위험관리, 거버넌스, 신뢰성평가 → AI 신뢰성 검인증 제도
> - (인증핵심) `위거신추` (위험관리·거버넌스·신뢰성 테스트·추적가능성)
> - (데이터/운영) `상이편오` (상세정보제공·이상데이터점검·편향제거·오픈소스보안/호환)
> - (방어/설명/사용) `편방설사` (편향제거·방어대책·설명제공·사용/상호작용설명)

### 🧠 상세 설명

### 1) 개념/정의

| 구분 | 설명 |
|:--|:--|
| **정의** | CAT는 AI 모델/시스템의 **신뢰성(Trustworthiness)**을 평가하여 **검증·인증**하는 제도 |
| **목적** | AI의 부정적 영향 최소화, 책임 있는 AI 도입/운영 기반 마련 |
| **인증 대상** | AI 모델, AI 시스템 |
| **인증 범위** | AI 거버넌스 체계, AI 제품 신뢰성(특성) |

---

### 2) 구성요소/기술요소 (2그룹 × 4개) `위거신추` / `상이편오`

#### 그룹 1: 인증 범위(대상/범위) `모시거신`

| 항목 | 설명 | 예시 |
|:--|:--|:--|
| **AI 모델** | 개발·제공하는 모델 자체 인증 | 모델 성능/안전성/편향 |
| **AI 시스템** | SW/HW 포함 시스템 인증 | 서비스/플랫폼/장비 |
| **AI 거버넌스 체계** | 정책·조직·프로세스 이행 점검 | 책임·권한·감사 |
| **AI 제품 신뢰성** | 신뢰성 특성 시험/평가/검증 | 투명/공정/안전 등 |

#### 그룹 2: 핵심 점검/평가 축 `위거신추`

| 항목 | 설명 | 예시 |
|:--|:--|:--|
| **위험관리(위)** | 위험 식별·분석·대응 프로세스 | 위험관리 계획/수행 |
| **거버넌스(거)** | 책임·권한·감시 체계 | 조직/역할/프로세스 |
| **신뢰성 테스트(신)** | 목표·범위·방법·데이터 정의 | 테스트 계획/수행 |
| **추적가능성(추)** | 기록·버전·변경 이력 확보 | 로그/버전관리 |

---

### 3) 점검 사항(대표 신뢰성 속성)

| 속성 | 의미(요지) |
|:--|:--|
| **투명성** | 모델·데이터 명세, 벤치마크 결과, AI 생성 콘텐츠 표시 |
| **책무성** | 규제 기반 책임성, 합의 기반 책임(역할/책임의 명확화) |
| **책임성** | 개인정보 출처·비식별화 데이터 사용 등 준수 여부 확인 |
| **저작권 보호** | 학습데이터 출처 및 저작권 확보 여부 확인 |
| **공정성** | 통계적 동등성 등 편향 관리 |
| **안전성** | 유해 오용 방지, 제어가능성, 안전기능(세이프가드) |
| **추적가능성** | 데이터/결과/기록 추적 가능(버전/이력) |
| **설명가능성** | 모델 설명력(설명 기법/근거) |
| **해석가능성** | 결과 해석력(사용자 관점 이해 가능) |
| **품질** | 정확성, 안정성, 강건성 |
| **보안** | 모델 보안, 데이터 보안, 시스템 보안 |

---

### 4) 인증 기준(요구사항 1~15) `위거신추` / `상이편오` / `편방설사`

> 아래 15개 요구사항은 CAT 점검/인증의 핵심 체크리스트로, 실무 관점에서는 **문서화(증적)**가 성패를 좌우합니다.

| 번호 | 요구사항 | 평가 내용(요약) |
|:--:|:--|:--|
| 1 | **AI 시스템 위험관리 계획·수행** `위` | 위험관리 요소·계획·수행 프로세스 명확성, 위험 식별·분석·평가·대응의 체계적 수행 |
| 2 | **AI 거버넌스 체계 구성** `거` | 모델/시스템 범위 정의, 책임·권한 구분, 운영 감시/관리/감독 체계, 지속 개선 여부 |
| 3 | **AI 시스템 신뢰성 테스트 계획 수립** `신` | 목표 명확성, 테스트 대상 기능/범위 명확성, 평가 방법(기준 포함)·환경·데이터 정의 |
| 4 | **AI 시스템 추적가능성 및 변경이력 확보** `추` | 데이터 출처/변환 정보 기록, 학습·알고리즘 변경 기록, 코드/시스템 버전관리, 성능 추적/분석, 변경 승인/검증, 롤백/복구 |
| 5 | **데이터 활용을 위한 상세 정보 제공** `상` | 메타데이터 관리정보 포함 여부, 정제/변환 규칙 명확성, 민감정보 포함 여부, 데이터 출처·수집 방법 명확성 |
| 6 | **데이터 건전성(무결성) 확보를 위한 이상 데이터 점검** `이` | 수집 단계 오류/누락/부정확 값 검증활동, 최적화 과정 변형/통계적 오류 검증활동, 데이터 변조/공격 탐지·방어 수단 |
| 7 | **수집·가공 학습데이터 편향 제거** `편` | 편향 특성/유형/기준 정의, 수집·가공 시 편향 제거 기술 도입 적정성, 라벨링 지침/교육/감독 이행 |
| 8 | **AI 오픈소스 라이브러리 보안성·호환성 점검** `오` | 오픈소스 선정 기준(성능/안정성/커뮤니티/문서화), 보안 검토(취약점 스캔/침투테스트 등)와 해결 절차, 버전·API 호환/성능 테스트 결과 |
| 9 | **AI 모델 편향 제거** `편` | 모델 편향 제거 기법 적용을 위한 분석 내용 식별, 편향 수준 정량 분석 수행 가능 여부 |
| 10 | **AI 모델 공격 방어 대책 수립** `방` | 가능한 모델 공격 유형 식별, 공격 영향도 파악, 방어 전략/대책 수립 여부 |
| 11 | **AI 모델 명세 및 추론 결과 설명 제공** `설` | 모델 명세의 구체성/충분성/정확성, 설명가능성 기법의 적절성, 결과 설명의 이해 용이성 및 신뢰도 제시 |
| 12 | **AI 시스템 구현 시 발생 가능한 편향 제거** `편` | 데이터 접근 방식/소스코드 구현 과정에서 편향 가능성 확인, UI/상호작용 방식으로 인한 편향 확인 |
| 13 | **AI 시스템 안전 모드 구현 및 문제 알림 절차** `사` | 안전모드 작동 기준/조건 및 동작상황, 해제 기준/절차, 문제 감지·식별 방법, 알림 방식/내용, 알림 수신자·역할 |
| 14 | **AI 설명에 대한 사용자 이해도 제고** `사` | 사용자 특성에 맞는 설명 방식 적용, 설명의 명확성/간결성(전문용어 최소화), 시각자료/다양한 설명 방식 활용 |
| 15 | **서비스 제공 범위 및 상호작용 대상 설명 제공** `사` | 서비스 약관·면책 조항 적절성, 이용정책(허용/금지) 적절성, 개인정보 수집·처리 정책 적절성, 실제 서비스 이용환경에서 정책의 일관 적용 |

---

### 5) CAT 1.0 vs CAT 2.0 (개요)

| 구분 | CAT 1.0(초기) | CAT 2.0(고도화) |
|:--|:--|:--|
| 평가 방식 | 문서·절차 중심 심사 비중 큼 | 실제 운영환경 기능/성능 시험 강화(실증 강화) |
| 적용 시점(메모) | 초기 도입 단계 | 2025년 4월부터 본격 적용(고도화 모델) |
| 기준 기반 | 표준/가이드라인 참고 | 국제표준 기반 평가 강화(위험관리/AIMS/거버넌스 등) |

---

### 6) 연계 표준(참고)

| 표준/문서 | 주요 초점 | CAT에서의 활용 포인트(요약) |
|:--|:--|:--|
| **ISO/IEC 22989:2022** | AI 개념·용어 | 범위/정의/용어 정렬(조직 내 기준 통일) |
| **ISO/IEC 23894:2023** | AI 위험관리 | 위험 식별·평가·대응·모니터링 체계화(요구사항 1) |
| **ISO/IEC 42001:2023** | AI 경영시스템(AIMS) | 조직 맥락/리더십/정책/성과평가/개선(요구사항 2) |
| **ISO/IEC 38507** | AI 거버넌스 | 책임·권한·윤리·이해관계자 소통(요구사항 2/15 연계) |

---

## 참고(출처/메모)

- CAT: TTA 주관 AI 신뢰성 검인증(Trustworthiness) 제도
- 암기법: `위거신추` / `상이편오` / `편방설사`
