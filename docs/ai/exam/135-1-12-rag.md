---
layout: default
title: 135회-1교시-12번 RAG(Retrieval-Augmented Generation)
parent: 📝 기출문제
grand_parent: AI (인공지능)
nav_order: 1352112
permalink: /docs/ai/exam/135-1-12-rag
---

# RAG(Retrieval-Augmented Generation)
{: .no_toc }

135회 정보관리기술사 1교시 12번
{: .label .label-blue }

1교시형 (단답형)
{: .label .label-red }

---

## 📚 목차
{: .no_toc .text-delta }

- [🎓 고딩 수준 설명](#-고딩-수준-설명)
- [🎯 기술사 수준 설명](#-기술사-수준-설명)

---

<details markdown="1">
<summary><h2 style="display:inline" id="-고딩-수준-설명">🎓 고딩 수준 설명 (클릭해서 펼치기)</h2></summary>

### 🔑 핵심 키워드 3개

| 키워드 | 설명 |
|:------|:-----|
| **검색(Retrieval)** | 외부 지식베이스에서 관련 정보를 찾아오는 것 |
| **증강(Augmented)** | 검색된 정보를 질문에 추가하여 강화 |
| **생성(Generation)** | LLM이 증강된 정보로 답변을 생성 |

---

### 📖 등장배경

```
🌐 과거: ChatGPT가 학습 이후 데이터를 모르거나 거짓말을 해요 (환각현상)

💡 문제: "최신 정보도 알고, 거짓말도 안 하게 할 수 없을까?"

✅ 해결: RAG로 외부 지식을 검색해서 답변에 활용!
   → 질문이 들어오면 관련 문서를 먼저 검색
   → 검색된 내용을 질문과 함께 LLM에 전달
   → 정확하고 신뢰성 있는 답변 생성!
```

---

### 📝 개념 정의

> **RAG(Retrieval-Augmented Generation)**: 생성형 AI 서비스를 외부 데이터를 검색하고 검색된 관련 데이터를 컨텍스트에 추가하여 AI 모델의 정확성과 신뢰성을 향상시키는 기술

| 개념 | 쉬운 비유 |
|:-----|:---------|
| **RAG** | 시험 볼 때 교과서를 참고하면서 답을 쓰는 것 |
| **Vector DB** | 책을 주제별로 정리해둔 도서관 |

---

### 🏗️ 기술요소 (2그룹 × 4개)

#### 그룹 1: RAG 절차 `문입정답출`

| 단계 | 설명 |
|:-----|:-----|
| **문**서변환 | 문서를 벡터로 변환/저장 |
| **입**력쿼리 | 질문으로 관련 문서 검색 |
| **정**보증강 | 검색 결과와 질문 결합 |
| **답**변생성 | LLM이 응답 생성 |
| **출**력생성 | 정제 및 형식화 |

#### 그룹 2: 핵심 기술 `인검생`

| 기술 | 설명 |
|:-----|:-----|
| **인**덱싱 | 벡터 인코딩, 인덱스 생성 |
| **검**색모델 | 관련 문서 검색 |
| **생**성모델 | LLM 기반 응답 생성 |

---

### ⭐ 차별점 키워드

**"환각현상(Hallucination) 해결"** - 외부 지식을 검색하여 사실에 기반한 답변 생성

---

### 🧾 6하원칙 요약

| 항목 | 내용 |
|:-----|:-----|
| **누가** | LLM 기반 서비스 개발자 |
| **언제** | 정확한 정보가 필요한 답변 생성 시 |
| **어디서** | 챗봇, 고객지원, 기업용 AI 서비스 |
| **무엇을** | 검색 증강 생성 기술 |
| **어떻게** | 검색→증강→생성 파이프라인 |
| **왜** | 환각현상 방지, 최신 정보 활용 |

</details>

---

## 🎯 기술사 수준 설명
{: #-기술사-수준-설명}

### 📌 핵심 암기 (Quick Reference)

{: .highlight }
> **RAG**: 검색증강, 환각방지, 외부지식활용 → LLM 정확성/신뢰성 향상 기술
> - (절차) `문입정답출` - 문서변환, 입력쿼리, 정보증강, 답변생성, 출력생성
> - (핵심기술) `인검생` - 인덱싱, 검색모델, 생성모델
> - (필요성) `지환범` - 지식단절, 환각현상, 범용성한계
> - (특징) `인생외` - 인덱싱VectorDB, 생성모델결합, 외부정보이용
> - ⭐ **차별점**: 환각현상(Hallucination) 해결과 LLM 서비스의 가치: > - 발생 가능한 불필요한 반복, 부정확한 정보, 잘못된 문맥 통합 등을 해결

---

<div class="exam-concept-block" markdown="1">

## 🧠 개념 영역


### 🔑 핵심 키워드 3개

| 키워드 | 설명 |
|:------|:-----|
| **환각현상(Hallucination)** | 사실에 입각하지 않은 답변을 그럴듯하게 생성하는 현상 |
| **Vector DB** | 문서를 벡터로 변환하여 저장하는 데이터베이스 |
| **Sentence Embedding** | 문장을 고정 길이 벡터로 변환하는 기술 |

---

### 📖 등장배경

```
🌐 과거: LLM의 환각현상과 지식단절 문제 발생

💡 문제: "학습 이후 데이터에 대해서는 품질 저하, 거짓 답변 생성"

✅ 해결: RAG로 외부 지식 검색 및 활용!
   → 대규모 언어 모델의 환각 현상을 감소
   → 상황인식을 통해 응답 생성
   → 검색결과를 활용하여 다양한 형식의 텍스트 생성 가능
```

---

### 📝 개념 정의

| 구분 | 정의 (22자 이내) |
|:-----|:----------------|
| **RAG** | 검색 기반 생성형 AI 정확도 향상 기술 |
| **Retrieval** | 외부 지식베이스에서 관련 정보 검색 |
| **Augmentation** | 검색 정보로 입력 쿼리 강화 |

---

### 🔄 RAG 개념도 (ASCII)

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    RAG(Retrieval-Augmented Generation) 메커니즘              │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│    ┌────────┐                    ┌─────────────────────┐                    │
│    │        │      질의          │    질의 + 컨텍스트    │      ┌────────┐   │
│    │ 사용자  │─────────────┬─────►│                     │─────►│  답변   │   │
│    │        │             │      │  LLM 파운데이션 모델  │      │        │   │
│    └────────┘             │      └─────────────────────┘      └────────┘   │
│         │                 │                ▲                               │
│         │                 │     ┌──────────┴──────────┐                    │
│         ▼                 │     │    프롬프트 증강      │                    │
│    ┌─────────┐            │     └──────────┬──────────┘                    │
│    │ 임베딩   │            │                │                               │
│    │  모델   │            │     ┌──────────┴──────────┐                    │
│    └────┬────┘            │     │     컨텍스트         │                    │
│         │                 │     └──────────┬──────────┘                    │
│         ▼                 │                │                               │
│    ┌─────────────────────────────────────────────────────────┐             │
│    │                      인덱싱                               │             │
│    │  ┌─────────┐    ┌─────────┐    ┌─────────┐              │             │
│    │  │  지식    │    │  임베딩  │    │  외부   │              │             │
│    │  │ 베이스  │◄───│  모델   │◄───│  지식   │              │             │
│    │  │(벡터DB) │    │        │    │        │              │             │
│    │  └─────────┘    └─────────┘    └─────────┘              │             │
│    └─────────────────────────────────────────────────────────┘             │
│                                                                              │
│   • 들어온 요청에 대해 외부 데이터(Knowledge Sources)를 검색                    │
│   • 기존 생성형 AI의 결과와 병합하여 생성형 AI 서비스를 향상                     │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

</div>

## 🏗️ 기술 영역

<div class="exam-tech-block" markdown="1">

### 🏗️ 구성요소

#### 그룹 1: RAG 필요성 `지환범`

| 필요성 | 설명 |
|:-------|:-----|
| **지**식단절 | 모델 학습 이후에 생성된 데이터에 대해서는 학습 부족으로 품질 저하 |
| **환**각현상 | 사실에 입각하지 않은 답변을 그럴듯하고 자연스럽게 하는 환각 증상 |
| **범**용성한계 | 다방면에 일정 수준 이상의 답변을 할 수 있지만, 특정 영역의 전문성 부족 |

---

#### 그룹 2: RAG 절차 `문입정답출`

| 단계 | 기술 요소 | 설명 |
|:-----|:---------|:-----|
| 1. **문**서 변환 & 저장 | Sentence Embedding, Vector DB | 문서를 Load→Split→Parsing 후 Dense Vector로 변환, Indexing하여 Vector DB에 저장 |
| 2. **입**력 쿼리 & 문서 검색 | Query, Document Retrieval | 검색 시스템 활성화, 쿼리 기반으로 말뭉치(corpus)에서 관련 문서/스니펫 검색 |
| 3. **정**보 증강 | Context Integration | 원래 입력과 검색된 관련 정보를 결합, 증강된 입력 형성 |
| 4. **답**변 생성 | Seq2Seq, BART, GPT | 강화된 입력을 LLM에 제공, 언어 모델이 응답 생성 |
| 5. **출**력 생성 | Refinement & Formatting | 생성 응답을 요구 사항에 맞게 정제/형식화, 최종 응답 전달 |

---

#### 그룹 3: 핵심 기술 `인검생`

| 핵심 기술 | 구성 요소 | 설명 |
|:---------|:---------|:-----|
| **인**덱싱(Indexing) | 데이터 정제, 청크 분할, 벡터 인코딩 | 데이터 소스에서 데이터를 얻고 인덱스를 생성하는 과정 |
| **검**색 모델(Retriever) | 하이브리드 검색, 재귀적 검색, 서브 쿼리 | 큰 텍스트 데이터베이스를 검색하는 컴포넌트, 역추적 프롬프트 |
| **생**성 모델(Generator) | LLM 기반 문서 생성 및 데이터화 | 검색된 내용의 중복/노이즈에 대응, 외부 지식 활용, 빠른 추론 속도 |

---

</div>

<div class="exam-bonus-block" markdown="1">

## ⭐ 차별점 키워드 (가산점 포인트)

{: .important }
> **환각현상(Hallucination) 해결과 LLM 서비스의 가치**
> - 발생 가능한 불필요한 반복, 부정확한 정보, 잘못된 문맥 통합 등을 해결
> - 임베딩, 상황검색 통해 정확도 향상 및 추론 통해 응답 강화
> - **개인화된 지원**: 사용자 맞춤형 응답 제공
> - **비용 효율성**: Fine-tuning 대비 저비용 고효율
> - **24시간 지원**: 실시간 정보 검색 기반 서비스

---

### 📈 상위 토픽 계층도

```
LLM 성능 향상 기법
├── 학습 기반
│   ├── Fine-Tuning (모델 재학습)
│   ├── RLHF (인간 피드백 강화학습)
│   └── Instruction Tuning
├── 추론 기반
│   ├── Prompt Engineering
│   ├── Chain-of-Thought
│   └── Few-shot Learning
└── 검색 기반
    └── RAG (Retrieval-Augmented Generation) ⭐
        ├── 인덱싱 (Indexing)
        │   ├── Document Loading
        │   ├── Text Splitting
        │   └── Vector Embedding
        ├── 검색 (Retrieval)
        │   ├── Similarity Search
        │   └── Hybrid Search
        └── 생성 (Generation)
            ├── Context Augmentation
            └── LLM Response
```

---

### 🔗 활용 분야

| 분야 | 활용 예시 |
|:-----|:---------|
| **기업 챗봇** | 사내 문서 기반 질의응답 시스템 |
| **고객 지원** | FAQ 및 제품 매뉴얼 기반 자동 응답 |
| **법률/의료** | 전문 문서 검색 기반 조언 시스템 |
| **교육** | 학습 자료 기반 튜터링 시스템 |
| **연구** | 논문 검색 및 요약 시스템 |

---

### ✅ 학습 체크리스트

- [ ] RAG의 정의 (검색 증강 생성) 설명 가능
- [ ] RAG 필요성 `지환범` 암기 (지식단절, 환각현상, 범용성한계)
- [ ] RAG 절차 `문입정답출` 암기 (문서변환, 입력쿼리, 정보증강, 답변생성, 출력생성)
- [ ] 핵심 기술 `인검생` 설명 가능 (인덱싱, 검색모델, 생성모델)
- [ ] Vector DB와 Sentence Embedding의 역할 설명 가능
- [ ] RAG vs Fine-Tuning 차이점 비교 설명 가능
- [ ] 환각현상(Hallucination)과 RAG의 해결 방식 설명 가능
- [ ] RAGaaS의 개념 설명 가능

</div>

<details markdown="1">
<summary><h3 style="display:inline">🧠 상세 설명 (클릭해서 펼치기)</h3></summary>

<details markdown="1">
<summary><h3 style="display:inline">🧠 상세 설명 (클릭해서 펼치기)</h3></summary>

### 📋 RAG 특징 `인생외`

| 특징 | 설명 |
|:-----|:-----|
| **인**덱싱, Vector DB 사용 | 문서를 벡터로 변환하여 효율적인 유사도 검색 |
| **생**성 모델 결합 | 검색 결과를 LLM에 전달하여 자연스러운 응답 생성 |
| **외**부정보이용, 검색 모델 | 학습되지 않은 최신 정보도 활용 가능 |

---

### 📊 RAG 진행 메커니즘

| 단계 | 활동 | 설명 |
|:-----|:-----|:-----|
| 1 | 프롬프트 | 사용자가 AI모델에 설명과 응답 요청 |
| 2 | 상황 별 검색(정보검색) | 쿼리나 작업이 입력되면, 활용 가능한 지식 베이스를 조회하여 쿼리와 관련된 문단/문서나 텍스트를 질의 |
| 3 | 프롬프트 증강(문맥제공) | 검색된 문단들은 추가적인 문맥이나 Data로 모델에 제공 |
| 4 | 추론(텍스트 생성) | 추가 문맥을 활용하여 모델은 더 정확하고 연관된 사실과 지식에 기반한 텍스트 출력을 생성 |
| 5 | 응답 | LLM은 실제로 정확한 정보와 함께 응답을 사용자에게 제공 |

---

### 📈 RAG as a Service (RAGaaS)

```
┌─────────────────────────────────────────────────────────────────┐
│                        Cloud Infra                               │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  ┌────────────┐                         ┌────────────┐          │
│  │ Vector DB  │                         │  Response  │          │
│  └─────┬──────┘                         └─────▲──────┘          │
│        │                                      │                 │
│  ┌─────▼──────┐                         ┌─────┴──────┐          │
│  │ Embedding  │                         │    LLM     │          │
│  │   Model    │                         │            │          │
│  └─────┬──────┘                         └─────▲──────┘          │
│        │                                      │                 │
│  ┌─────▼──────┐                   ┌───────────┴───────────┐     │
│  │Preprocess  │◄──────────────────│Prompt + Query +       │     │
│  │ Documents  │                   │Retrieved Documents    │     │
│  └────────────┘                   └───────────────────────┘     │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
        ▲                                         │
        │ REST API                                │
        │ RAG Pipelines                           ▼
   ┌────┴────┐                              ┌──────────┐
   │Knowledge│                              │User Query│
   │ Sources │                              │          │
   └─────────┘                              └──────────┘

• LLM의 성능을 향상시키기 위해 외부 지식을 검색 및 활용 기능을 제공하는 클라우드 서비스 모델
```

---

</details>

</details>
