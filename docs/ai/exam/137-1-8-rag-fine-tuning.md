---
layout: default
title: 137회-1교시-8번 RAG(Retrieval Augmented Generation)과 Fine Tuning
parent: 📝 기출문제
grand_parent: AI (인공지능)
nav_order: 1371108
permalink: /docs/ai/exam/137-1-8-rag-fine-tuning
---

# RAG(Retrieval Augmented Generation)과 Fine Tuning
{: .no_toc }

137회 정보관리기술사 1교시 8번 (컴시응)
{: .label .label-blue }

1교시형 (단답형) - 비교형
{: .label .label-red }

---

## 📚 목차
{: .no_toc .text-delta }

- [🎓 고딩 수준 설명](#-고딩-수준-설명)
- [🎯 기술사 수준 설명](#-기술사-수준-설명)

---

<details markdown="1">
<summary><h2 style="display:inline" id="-고딩-수준-설명">🎓 고딩 수준 설명 (클릭해서 펼치기)</h2></summary>

### 🔑 핵심 키워드 3개

| 키워드 | 설명 |
|:------|:-----|
| **검색 증강** | AI가 답변 전에 외부 자료를 먼저 찾아보는 것 |
| **파라미터 조정** | AI 모델의 두뇌 구조를 직접 바꾸는 것 |
| **할루시네이션** | AI가 없는 정보를 그럴듯하게 지어내는 현상 |

---

### 📖 등장배경

```
🌐 과거: ChatGPT 같은 LLM은 학습 데이터가 오래되면 최신 정보를 모름

💡 문제: "AI가 거짓말을 해요! 없는 정보도 자신있게 말해요!"

✅ 해결: 두 가지 방법으로 해결하자!
   → RAG: 답변 전에 최신 자료를 검색해서 참고하게 하자!
   → Fine-Tuning: AI 두뇌를 우리 업무에 맞게 재교육하자!
   → 상황에 맞게 선택 활용
```

---

### 📝 개념 정의

> **RAG**: AI가 답하기 전에 외부 문서를 검색해서 참고하는 기술
> 
> **Fine-Tuning**: AI 모델을 특정 분야 데이터로 재학습시키는 기술

| 개념 | 쉬운 비유 |
|:-----|:---------|
| **RAG** | 오픈북 시험 - 책을 보면서 답변 작성 |
| **Fine-Tuning** | 전문가 양성 과정 - 특정 분야를 깊이 공부시킴 |

---

### 🏗️ 기술요소 (2그룹 × 4개)

#### 그룹 1: RAG 핵심 `질유관추`

| 요소 | 설명 |
|:-----|:-----|
| **질**문 임베딩 | 질문을 숫자 벡터로 변환 |
| **유**사성 검색 | Vector DB에서 관련 문서 찾기 |
| **관**련도 순위 | 검색 결과 중요도 정렬 |
| **추**론/생성 | LLM이 검색 결과로 답변 생성 |

#### 그룹 2: Fine-Tuning 핵심 `데모하평`

| 요소 | 설명 |
|:-----|:-----|
| **데**이터셋 준비 | 학습용 데이터 수집/전처리 |
| **모**델 선택 | 기반 모델(Base Model) 결정 |
| **하**이퍼파라미터 | 학습률, 배치 크기 설정 |
| **평**가/튜닝 | 성능 측정 및 최적화 |

---

### ⭐ 차별점 키워드

**"모델 변경 여부"** - RAG는 모델 그대로 두고 외부 지식 활용, Fine-Tuning은 모델 파라미터 직접 수정

---

### 🧾 6하원칙 요약

| 항목 | RAG | Fine-Tuning |
|:-----|:----|:------------|
| **누가** | OpenAI, Meta (2020) | Google, OpenAI |
| **언제** | 최신 정보가 필요할 때 | 도메인 전문성이 필요할 때 |
| **어디서** | 챗봇, FAQ, 문서 검색 | 법률/의료 AI, 고객센터 |
| **무엇을** | 외부 지식베이스 검색 후 답변 | 모델 파라미터 재학습 |
| **어떻게** | 임베딩 → 검색 → 증강 → 생성 | 데이터 준비 → 학습 → 평가 |
| **왜** | 최신 정보 반영, 할루시네이션 감소 | 도메인 특화, 일관된 스타일 |

</details>

---

## 🎯 기술사 수준 설명
{: #-기술사-수준-설명}

### 📌 핵심 암기 (Quick Reference)

{: .highlight }
> **RAG & Fine-Tuning**: 외부지식검색, 파라미터조정, 할루시네이션방지 → LLM 성능 향상 기법
> - (RAG 절차) `질유관추프텍` - 질문임베딩, 유사성검색, 관련도순위, 추론, 프롬프트엔지니어링, 텍스트생성
> - (Fine-Tuning 절차) `데모하파평` - 데이터셋준비, 모델선택, 하이퍼파라미터, 파인튜닝학습, 평가
> - (RAG 프레임워크) `L-L-H-R` - LangChain, LlamaIndex, Haystack, RAGFlow
> - (Fine-Tuning 프레임워크) `P-U-I-O` - PEFT, Unsloth, InstructLab, OpenAI API
> - (비교) `개특장단활프` - 개념, 특징, 장점, 단점, 활용, 프레임워크

---

### 🔑 핵심 키워드 3개

| 키워드 | 설명 |
|:------|:-----|
| **검색 증강 생성** | 외부 지식베이스를 검색하여 프롬프트에 증강, LLM 정확성과 신뢰성 향상 |
| **파라미터 조정** | 사전학습된 모델의 가중치를 특정 도메인 데이터셋으로 재학습 |
| **할루시네이션** | LLM이 사실이 아닌 정보를 생성하는 현상, RAG로 완화 가능 |

---

### 📝 개념 정의

| 구분 | 정의 (22자 이내) |
|:-----|:----------------|
| **RAG** | 외부 지식 검색 후 프롬프트 증강 생성 기술 |
| **Fine-Tuning** | 도메인 데이터로 모델 파라미터 재학습 기법 |

---

### 🏗️ 구성요소 (핵심 암기법 상세) `질유관추프텍` / `데모하파평`

#### 그룹 1: RAG 절차 `질유관추프텍`

| 단계 | 절차 | 설명 | 예시 |
|:-----|:-----|:-----|:-----|
| 검색단계 | **질**문 임베딩 | 자연어 질문을 수치적 벡터로 표현 | Sentence Embedding |
| 검색단계 | **유**사성 검색 | Vector DB에서 질문과 데이터 문서의 유사성 검색 | Cosine Similarity |
| 검색단계 | **관**련도 순위 결정 | 가장 관련성 높은 데이터 순위 재조정, 메타데이터 필터링 | ReRank 모델 |
| 생성단계 | **추**론 | Vector DB에서 관련 문서 조각을 가져와 최종 프롬프트 구성 | Top-K 문서 |
| 생성단계 | **프**롬프트 엔지니어링 | 검색된 정보 기반 사용자 질문에 적절히 답변하도록 구성 | 시스템 프롬프트 |
| 생성단계 | **텍**스트 응답 생성 | 생성된 텍스트가 문법적으로 정확하고 일관성 있는지 확인 | 후처리 |

#### 그룹 2: Fine-Tuning 절차 `데모하파평`

| 단계 | 절차 | 설명 | 예시 |
|:-----|:-----|:-----|:-----|
| 사전단계 | **데**이터셋 준비 | 추가 학습 데이터셋 수집, 저장 및 전처리 수행 | 법률 문서, 의료 기록 |
| 사전단계 | **모**델 선택 | 데이터셋 특성 기반 사전 학습모델 선택 | Llama, GPT-3.5 |
| 파인튜닝 | **하**이퍼파라미터 설정 | 학습률, 배치 크기, 훈련 에포크 수 결정 | Grid Search, Bayesian |
| 파인튜닝 | **파**인튜닝 학습 | 지도/비지도 파인튜닝, 전이학습, 미세조정 | LoRA, PEFT |
| 파인튜닝 | **평**가/튜닝 | Accuracy, F1-score, BLEU, ROUGE 등 성능 평가 | BERTScore |

---

### 📊 RAG vs Fine-Tuning 비교 `개특장단활프`

| 구분 | RAG | Fine-Tuning |
|:-----|:----|:------------|
| **개**념 | 외부 지식베이스 **검색 후 프롬프트에 증강**하여 최신/도메인 지식 반영 | 특정 도메인 데이터셋으로 **모델 파라미터 직접 조정** |
| **특**징 | 모델 변경 없음 (Zero-shot/Few-shot), 최신 데이터 반영 가능, 데이터 업데이트 용이 | 모델 파라미터 직접 조정, 특화 모델 생성, 데이터 변경 시 재학습 필요 |
| **장**점 | 최신 데이터 반영, 비용 효율적, 도메인 지식 관리 용이 | 응답 일관성 ↑, 특정 스타일/전문성 강화, 오프라인 동작 |
| **단**점 | 검색 품질에 따라 성능 좌우, 검색 인덱스 관리 필요 | 재학습 비용 큼 (시간·GPU), 오버피팅 가능성 |
| **활**용 | 챗봇, 기업 FAQ, 실시간 문서 검색 기반 질의응답 | 법률 AI, 의료 AI, 고객센터 전용 챗봇, 특정 언어/스타일 모델 |
| **프**레임워크 | LangChain, LlamaIndex, Haystack, RAGFlow | PEFT, Unsloth, InstructLab, OpenAI API |

---

### 🛠️ 대표 프레임워크

#### RAG 프레임워크 `L-L-H-R`

| 프레임워크 | 설명 |
|:----------|:-----|
| **L**angChain | LLM, VectorDB의 조합된 파이프라인 구조, Python/JS 지원 |
| **L**lamaIndex | 외부 문서 인덱싱/검색 최적화 지원 (구 GPT Index) |
| **H**aystack | Deepset의 오픈소스 모듈식 RAG 프레임워크 |
| **R**AGFlow | RAG 파이프라인 구축/관리 시각적 로우코드 인터페이스 제공 |

#### Fine-Tuning 프레임워크 `P-U-I-O`

| 프레임워크 | 설명 |
|:----------|:-----|
| **P**EFT | 효율적인 파인튜닝 수행을 위한 Huggingface 라이브러리 |
| **U**nsloth | Llama3에 최적화된 QLoRA 기반 파인튜닝 도구 |
| **I**nstructLab | Red Hat의 합성데이터 활용 Fine Tuning 프레임워크 |
| **O**penAI API | ChatGPT 대상 파인튜닝 지원 API 도구 |

---

### ⭐ 차별점 키워드 (가산점 포인트)

{: .important }
> **LangChain & LangGraph 생태계**
> - LangChain: LLM 애플리케이션 개발 특화 오픈소스 프레임워크
> - LangGraph: 멀티에이전트 워크플로우 구축 (OSS)
> - LangSmith: 디버깅, 프롬프트 관리, 테스트, 모니터링 (Commercial)
> - LangGraph Cloud: 배포 플랫폼 (Commercial)

---

<details markdown="1">
<summary><h3 style="display:inline">🧠 상세 설명 (클릭해서 펼치기)</h3></summary>

#### 📖 등장배경

```
🌐 과거: LLM은 학습 시점 이후 정보를 알지 못하고, 특정 도메인 지식이 부족

💡 문제: "할루시네이션 발생, 최신 정보 반영 불가, 도메인 전문성 부족"

✅ 해결: 두 가지 접근법으로 LLM 성능 향상!
   → RAG: 외부 지식베이스 검색으로 최신/정확한 정보 반영
   → Fine-Tuning: 도메인 데이터로 모델 파라미터 직접 조정
   → LangChain, PEFT 등 프레임워크로 실용화
```

---

#### 🔄 RAG 구조도 (ASCII)

```
┌─────────────────────────────────────────────────────────────────────┐
│                         RAG Architecture                             │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│   ┌──────────┐    ①Prompt+Query     ┌─────────────────────────┐    │
│   │          │ ───────────────────→ │                         │    │
│   │  사용자   │                      │      LLM (Foundation    │    │
│   │          │ ←─────────────────── │         Model)          │    │
│   └──────────┘    ⑤생성된 응답       └───────────┬─────────────┘    │
│                                                  │                   │
│                                         ④Prompt+Query+증강컨텍스트   │
│                                                  ↑                   │
│   ┌──────────────────────────────────────────────┴───────────────┐  │
│   │                    프롬프트 증강                               │  │
│   └──────────────────────────────────────────────────────────────┘  │
│                             ↑ ③증강된 컨텍스트 (관련정보)            │
│   ┌───────────────────────────────────────────────────────────────┐ │
│   │                        인덱싱                                  │ │
│   │  ┌─────────────┐     ┌─────────────┐     ┌─────────────────┐  │ │
│   │  │   지식       │     │  벡터 DB    │     │  임베딩 모델    │  │ │
│   │  │  베이스      │ ──→ │  (Vector)   │ ←── │  (Embedding)    │  │ │
│   │  └─────────────┘     └─────────────┘     └─────────────────┘  │ │
│   │        외부지식              ②Query                            │ │
│   └───────────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────────────┘
```

---

#### 🔄 Fine-Tuning 구조도 (ASCII)

```
┌─────────────────────────────────────────────────────────────────────┐
│                      Fine-Tuning Architecture                        │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│   ┌─────────────┐      Transfer         ┌─────────────────┐         │
│   │  Massive    │      Learning         │    Base LLM     │         │
│   │   Data      │ ───────────────────→  │    (사전학습)    │         │
│   │ (대규모)     │                       └────────┬────────┘         │
│   └─────────────┘                                │                   │
│                                                  │ Fine-tuning       │
│   ┌─────────────┐                                ↓                   │
│   │  Train Data │ ───────────────────→  ┌─────────────────┐         │
│   │ (도메인 특화) │    Small Data        │  Fine-tuned     │ ──→ User│
│   └─────────────┘                       │    Model        │   Query │
│                                         └────────┬────────┘  Answer │
│                                                  │                   │
│                                         Re-Finetuning                │
│                                                  ↓                   │
│                                         ┌─────────────────┐         │
│                                         │  Validation &   │         │
│                                         │   Monitoring    │         │
│                                         └─────────────────┘         │
└─────────────────────────────────────────────────────────────────────┘
```

---

#### 📈 상위 토픽 계층도

```
LLM 성능 향상 기법
├── 외부 지식 활용 (모델 변경 X)
│   ├── RAG ⭐
│   │   ├── 검색 단계 (질문임베딩, 유사성검색, 관련도순위)
│   │   └── 생성 단계 (추론, 프롬프트엔지니어링, 텍스트생성)
│   ├── In-Context Learning
│   └── Prompt Engineering
├── 모델 파라미터 조정
│   ├── Fine-Tuning ⭐
│   │   ├── Full Fine-Tuning
│   │   └── PEFT (Parameter-Efficient Fine-Tuning)
│   │       ├── LoRA
│   │       ├── QLoRA
│   │       └── Adapter
│   └── Transfer Learning
└── 프레임워크
    ├── RAG: LangChain, LlamaIndex, Haystack
    └── Fine-Tuning: PEFT, Unsloth, DeepSpeed
```

---

#### ✅ 학습 체크리스트

- [ ] RAG의 검색 단계 3가지 절차 `질유관` 설명 가능
- [ ] RAG의 생성 단계 3가지 절차 `추프텍` 설명 가능
- [ ] Fine-Tuning의 5단계 절차 `데모하파평` 설명 가능
- [ ] RAG vs Fine-Tuning 비교 6가지 구분자 `개특장단활프` 암기
- [ ] RAG 프레임워크 4가지 `L-L-H-R` 암기 (LangChain, LlamaIndex, Haystack, RAGFlow)
- [ ] Fine-Tuning 프레임워크 4가지 `P-U-I-O` 암기 (PEFT, Unsloth, InstructLab, OpenAI API)
- [ ] 할루시네이션 해결에 RAG가 효과적인 이유 설명 가능

</details>
